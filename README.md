Question 1:
The Turing 1950s paper is considered an important building block in the field of artificial intelligence, the premise of the paper being, ‘Can machines think?’ To test this, he proposes a test called imitation games, also referred to as the Turing test, which, to this date, is valid. In the paper, he answers some of the objections to his own opinions.
A few of those observations, I feel, are still somewhat valid, despite so much advancement in the field of AI. In the paper, Turing defends the lack of diversity in the behaviour of machines by stating that at the moment storage is limited, but even when we have so much storage and computing power, machines are still limited in their behaviour. For example, ChatGPT is a large language model that is capable but still limited; it can write code, tell stories, answer your questions, etc., but cannot perform a web lookup. These elaborate systems only do as much as they are programmed for; hence, to date, we do not have a machine that can be good or even do multiple non-related things. In his paper, Turing quotes Professor Jefferson: "Not until a machine can write a sonnet or compose a concerto because of thoughts and emotions felt, and not by the chance fall of symbols, could we agree that machine equals brain" and claims that this is a solipsist point of view (a theory holding that the self can know nothing but its modifications and that the self is the only existent thing), and if so, we can't even be sure that anyone other than us can feel his or her self-thinking, but as it is an accepted fact that all humans think, we should not omit machines from this belief. I think Professor Jefferson's statement is still valid because if we consider large language models like ChatGPT, Gemini, etc., they are capable of writing poems and prose, but even though we cannot prove it, intuitively we know that text produced by such models is mostly the output of a phenomenological programme that is designed to piece words together in proper context and not from emotional experiences. 
In the paper, Turing predicts that by the year 2000, a computer will have a 30% chance of passing a five-minute Turing test with an unskilled interrogator. I think this prediction holds true because in today's day and age, when material online is filled with AI-generated content, from articles to images, it is difficult for the novice eye to distinguish it from human-generated content. 



Question 2:
1. Playing a decent game of table tennis (Ping-Pong)
According to AI literature computers cannot play table tennis like humans yet. While AI has witnessed remarkable progress across various domains, replicating human level or a decent level of table tennis proficiency remains a challenging obstacle. Accurately analyzing the balls dynamics is important to play. However, real world factors like lighting camera limitations and spin can bring uncertainty and errors in object detection and tracking. Table tennis is a dynamic game demanding real-time decision-making game based on many factors like ball state, opponents’ position and context of the game. Current AI models lack the understanding of these complex dynamics. Learning things in pretend situations, like video games, doesn't always work the same way in real life. This is because the pretend world might not have the same rules as the real world, and things can be different. For example, the way things move, the accuracy of sensors, and unexpected things happening in real life can be very different from what the computer learns in simulations. Even though computers are really good at following set patterns and strategies, humans are even better at being creative and changing how they play based on who they're playing against and how the game is going. Making computers act as flexible and adaptable as humans is still a hard thing to do.

2. Playing a decent game of bridge at a competitive level
AI has shown promise in card games like bridge. Programs like "Bridge Baron" and "Gin Rummy" have demonstrated strong performance, but mastering the strategic depth and partnership dynamics of competitive bridge is still a work in progress.

3. Writing an intentionally funny story
Making people laugh is not easy because humour is complicated. It depends on everyone understanding the same culture, the right timing, and the situation. Even though computers are getting better at understanding language, it's still hard for them to intentionally create funny things. Computers struggle to grasp the deeper meaning and intent behind humour. They can process words, but not necessarily the emotions, cultural references, and shared experiences that make                  something funny. Humour usually works by surprising people or doing something unexpected. Although AI can come up with different combinations of things, being truly original and witty may be difficult for them right now. Humour varies a lot from person to person and culture to culture. What one group of people finds funny, another might not. This makes it hard for AI to make universally funny stories without help from humans who understand different cultures. Based on the current literature, computers can't truly write intentionally funny stories in the same way humans do. Based purely on my personal experience, during a conversation with Apple's Siri, I discovered that it can make funny comments or share short stories that might bring laughter or lighten the mood. Let's see what AI literature has to say about this. Siri has a big collection of pre-written responses in its system. Some of these are made to be funny, using humor styles. It may seem like Siri is making clever jokes, but it's not creating true creative humor like a person would. Siri can analyze your past interactions and preferences to tailor its responses accordingly. If you often respond positively to playful comments, it might choose those responses more often, giving the impression of a funny personality. Siri can generate some text based on random combinations of words and phrases. While these might occasionally happen to be funny by chance, they often lack the specific context and intent              required for true humor.

4. Giving competent legal advice in a specialized area of law 
AI tools can assist with legal research, document review, and even drafting contracts. However, providing specialized legal advice requires deep understanding, empathy, and ethical considerations that AI currently cannot fully replicate.

6. Discovering and proving new mathematical theorems
Scientists have for the first time used artificial intelligence to suggest and prove new mathematical theorems. The potential breakthrough came in a collaboration between mathematicians who specialize in pure mathematics at the universities of Oxford and Sydney, alongside Google-owned Deep Mind. Machine learning provides a powerful framework that can uncover interesting and provable conjectures in areas where a large amount of data is available, or where the objects are too large to study with classical methods. Computers can check all possible cases to prove or disprove a theorem. This is a brute-force approach (algorithmic paradigm that consists of systematically checking all possible candidates for whether or not each candidate satisfies the problems statement) best suited for well-defined problems with limited possibilities. AI algorithms can analyze vast amounts of mathematical data to identify patterns and suggest new conjectures or theorems. 
Here is just a handful of the many computer-based discoveries that could be mentioned:
      - A new formula for pi with the property that it permits one to rapidly calculate binary or hexadecimal digits of pi at an arbitrary starting position, without needing to calculate digits that came before.
      - Evaluations of Euler sums in terms of simple mathematical expressions.
      - A new result for Mordell’s cube sum problem.

7. Perform a surgical operation
AI is making inroads in surgical assistance, with robots like the da Vinci Surgical System aiding in precise procedures. However, the full autonomy of performing complex surgeries without human oversight is not yet a reality.

8. Unload any dishwasher in any home
This task involves understanding the context of a specific home's layout and the arrangement of dishes, which is currently beyond the capabilities of AI. It requires real-time adaptation and physical dexterity that AI lacks.

9. Construct a building
AI can assist in architectural design and project management, but the actual construction involves physical labour, coordination, and problem-solving that AI cannot fully automate. Human expertise and on-site decision-making are still crucial.



Question 3:
Domain: Weather Prediction using Regression
Here the Agent, looks at a bunch of past weather information to figure out how to predict what the weather will be like in the future. It uses a Machine Learning algorithm called regression, which helps it understand the connections between the things that happened before like temperature, humidity, etc. and what the weather will be. The idea is to learn from the past to make really good predictions about the future weather. Fully accessible, with complete historical weather data available. Deterministic in the sense that it’s affected by past conditions. However, it's not completely predictable because there's randomness and chaos in the system. Each prediction can be considered an episode, with a defined start (historical data) and end (predicted future). The underlying relationships between data and weather patterns remain constant over time. Both historical data and future predictions involve continuous values e.g. temperature, humidity. Learning agent would be the best for this domain as this kind keeps getting better with experience, which is great for understanding tricky weather patterns and always getting better at predicting the weather.




Question 4:
1. An agent that senses only partial information about the state cannot be perfectly rational.
False. An agent with limited information can still be perfectly rational by making the best possible decision. For e.g. in chess the agent may not have complete information about the opponent but it can still make the best possible moves based on the information it has.

2. There exist task environments in which no pure reflex agent can behave rationally.
True. Pure reflex agents react to the current situation without taking in notice the past experiences. For e.g. in rat and maze problem after reaching a dead agent with no possible moves the agent will not backtrack as it does not have past information.

3. There exists a task environment in which every agent is rational.
False. Not every task environment allows for rational behaviour by every agent.

4. The input to an agent program is the same as the input to the agent function.
False. The agent program executes the agent function so the input might differ. The program may preprocess or filter data before passing on the information to the function. For e.g. in NLP input to the function may be just a sentence or two. But to the program the input is different as sentence tokenization is done, punctuation’s, stop words are removed.

5. Every agent function is implementable by some program/machine combination.
False. Some functions may require resources or information beyond current available tech.

6. Suppose an agent selects its action uniformly at random from the set of possible actions. There
exists a deterministic task environment in which this agent is rational.
True. If the task environment is such that all possible actions yield the same outcome, then selecting actions at random would still be rational. For example, in a simple environment where all paths lead to the goal state with equal cost, a random action selection is as good as any other strategy.

7. It is possible for a given agent to be perfectly rational in two distinct task environments.
True. An agent can be perfectly rational in multiple task environments if its decision-making process is optimal for the given conditions. For example, a navigation agent could be perfectly rational in both a city map environment and a rural map environment if it can find the shortest path in both cases.
